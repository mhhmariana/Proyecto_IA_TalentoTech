{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhhmariana/Proyecto_IA_TalentoTech/blob/main/Pred_Guarde.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLaTn_LOVV7n"
      },
      "outputs": [],
      "source": [
        "# Instalar Librerias neceasarias\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libreria para Google Drive\n",
        "!pip install gdown\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "qgxuYVyIW2_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/12cIekao280xCk665h2GZXMBdsbCucA9H/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1pnxqtEA0b3lf4nwg-6aj4KFxSAb-M0WP/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1X9sd_2WhoYopgsDy33_Xsvo2XpBMUXN7/view?usp=sharing\n",
        "# https://drive.google.com/file/d/17Ng6GFfDaEghL46CO6ifHV5MB7_UKhcO/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1TwPNIe-LqaFZPflW23HQV_oHZjmVan7O/view?usp=sharing\n",
        "\n",
        "# Lista de IDs de archivos de Google Drive para los diferentes años\n",
        "# Reemplaza estos con los IDs reales de tus archivos CSV\n",
        "file_ids = [\n",
        "    '12cIekao280xCk665h2GZXMBdsbCucA9H', # Ejemplo de ID de archivo para un año\n",
        "    '1pnxqtEA0b3lf4nwg-6aj4KFxSAb-M0WP', # Reemplaza con tu ID de archivo\n",
        "    '1X9sd_2WhoYopgsDy33_Xsvo2XpBMUXN7', # Reemplaza con tu ID de archivo\n",
        "    '17Ng6GFfDaEghL46CO6ifHV5MB7_UKhcO', # Reemplaza con tu ID de archivo\n",
        "    '1TwPNIe-LqaFZPflW23HQV_oHZjmVan7O', # Reemplaza con tu ID de archivo\n",
        "    # Agrega más IDs de archivo según sea necesario\n",
        "]\n",
        "\n",
        "# Lista para almacenar DataFrames individuales\n",
        "dataframes_list = []\n",
        "\n",
        "# Iterar a través de cada ID de archivo, descargar y leer el CSV\n",
        "for file_id in file_ids:\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    try:\n",
        "        temp_df = pd.read_csv(url)\n",
        "        dataframes_list.append(temp_df)\n",
        "        print(f\"Datos leídos exitosamente del archivo con ID: {file_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer los datos del archivo con ID: {file_id} - {e}\")\n",
        "\n",
        "\n",
        "# Concatenar todos los DataFrames en uno solo\n",
        "if dataframes_list:\n",
        "    data = pd.concat(dataframes_list, ignore_index=True)\n",
        "    print(\"\\n¡Todos los datos combinados exitosamente!\")\n",
        "else:\n",
        "    data = pd.DataFrame()\n",
        "    print(\"\\nNo se cargaron datos.\")"
      ],
      "metadata": {
        "id": "PaLvMQrdW4v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exraer los datos del archivo y poderlos visualizar en una tabla ordenada\n",
        "display(data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kao2NT0nXXUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna 'fecha' a datetime\n",
        "data['fecha'] = pd.to_datetime(data['fecha'])\n",
        "\n",
        "# Extraer características de la fecha\n",
        "data['año'] = data['fecha'].dt.year\n",
        "data['mes'] = data['fecha'].dt.month\n",
        "data['dia'] = data['fecha'].dt.day\n",
        "data['dia_semana_num'] = data['fecha'].dt.dayofweek # Lunes=0, Domingo=6\n",
        "\n",
        "# Codificar variables categóricas (dia_semana, motivo_estancia, condicion_climatica, evento_especial)\n",
        "data_encoded = pd.get_dummies(data, columns=['dia_semana', 'motivo_estancia', 'condicion_climatica', 'evento_especial'], drop_first=True)\n",
        "\n",
        "# Eliminar la columna 'fecha' original ya que hemos extraído las características\n",
        "data_processed = data_encoded.drop('fecha', axis=1)\n",
        "\n",
        "# Reordenar columnas para mostrar las de fecha primero\n",
        "date_cols = ['año', 'mes', 'dia', 'dia_semana_num']\n",
        "other_cols = [col for col in data_processed.columns if col not in date_cols]\n",
        "data_processed = data_processed[date_cols + other_cols]\n",
        "\n",
        "#Mostrar los datos procesados\n",
        "display(data_processed)"
      ],
      "metadata": {
        "id": "cXvkoRr1bkBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c2aa653"
      },
      "source": [
        "# Definir las variables objetivo y sus tipos (regresión o clasificación)\n",
        "# Corregimos el nombre de la columna 'evento_especial' a 'evento_especial_True' después de la codificación one-hot\n",
        "target_variables = {\n",
        "    'numero_perros_teckel': 'regression',\n",
        "    'estancias_largas': 'regression',\n",
        "    'temperatura_celsius': 'regression',\n",
        "    'dia_semana_Lunes': 'classification',\n",
        "    'dia_semana_Martes': 'classification',\n",
        "    'dia_semana_Miércoles': 'classification',\n",
        "    'dia_semana_Jueves': 'classification',\n",
        "    'dia_semana_Viernes': 'classification',\n",
        "    'dia_semana_Sábado': 'classification',\n",
        "    'condicion_climatica_Nublado': 'classification',\n",
        "    'condicion_climatica_Soleado': 'classification',\n",
        "    'motivo_estancia_Trabajo': 'classification',\n",
        "    'motivo_estancia_Vacaciones': 'classification'\n",
        "}\n",
        "\n",
        "# Las características (X) serán todas las columnas en data_processed excepto las variables objetivo\n",
        "features = [col for col in data_processed.columns if col not in target_variables.keys()]\n",
        "X = data_processed[features]\n",
        "\n",
        "# Diccionario para almacenar los modelos entrenados\n",
        "trained_models = {}\n",
        "\n",
        "# Importar los modelos necesarios\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Entrenar un modelo para cada variable objetivo\n",
        "for target_variable, model_type in target_variables.items():\n",
        "    y = data_processed[target_variable]\n",
        "\n",
        "    if model_type == 'regression':\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    elif model_type == 'classification':\n",
        "        # Para clasificación, necesitamos asegurarnos de que la variable objetivo es numérica (0 o 1)\n",
        "        # y que tiene al menos 2 clases.\n",
        "        if y.nunique() > 1:\n",
        "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        else:\n",
        "            print(f\"Saltando el entrenamiento para '{target_variable}' ya que solo tiene una clase.\")\n",
        "            continue\n",
        "    else:\n",
        "        print(f\"Tipo de modelo desconocido para '{target_variable}'. Saltando.\")\n",
        "        continue\n",
        "\n",
        "    model.fit(X, y)\n",
        "    trained_models[target_variable] = model\n",
        "\n",
        "print(\"Modelos entrenados con éxito para las variables objetivo especificadas.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "740274cc"
      },
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Función para preprocesar una fecha futura\n",
        "def preprocess_future_date(future_date_str, X_columns):\n",
        "    \"\"\"\n",
        "    Preprocesa una cadena de fecha futura para que coincida con el formato de las características de entrenamiento (X_columns).\n",
        "    \"\"\"\n",
        "    future_date = pd.to_datetime(future_date_str)\n",
        "\n",
        "    # Crear un DataFrame con la fecha futura y extraer características numéricas de la fecha\n",
        "    future_data = pd.DataFrame({\n",
        "        'año': [future_date.year],\n",
        "        'mes': [future_date.month],\n",
        "        'dia': [future_date.day],\n",
        "        'dia_semana_num': [future_date.weekday()] # Lunes=0, Domingo=6\n",
        "    })\n",
        "\n",
        "    # Crear un DataFrame vacío con las mismas columnas que X\n",
        "    future_processed = pd.DataFrame(columns=X_columns, index=[0])\n",
        "\n",
        "    # Llenar las columnas numéricas de fecha\n",
        "    for col in ['año', 'mes', 'dia', 'dia_semana_num']:\n",
        "        if col in future_processed.columns:\n",
        "            future_processed[col] = future_data[col]\n",
        "\n",
        "    # Para las columnas one-hot encoded, establecer el valor a True para la categoría correspondiente\n",
        "    # y False para las demás. Esto requiere inferir la categoría a partir de la fecha.\n",
        "\n",
        "    # Inferir día de la semana\n",
        "    day_of_week_map = {\n",
        "        0: 'Lunes', 1: 'Martes', 2: 'Miércoles', 3: 'Jueves',\n",
        "        4: 'Viernes', 5: 'Sábado', 6: 'Domingo'\n",
        "    }\n",
        "    predicted_day_name = day_of_week_map[future_date.weekday()]\n",
        "    if f'dia_semana_{predicted_day_name}' in future_processed.columns:\n",
        "         future_processed[f'dia_semana_{predicted_day_name}'] = True\n",
        "    # Si Domingo fue la columna eliminada por drop_first y es el día predicho,\n",
        "    # todas las otras columnas dia_semana_ serán False, lo cual es correcto.\n",
        "\n",
        "    # Para motivo_estancia, condicion_climatica, evento_especial,\n",
        "    # no podemos inferirlos solo de la fecha. Necesitamos un enfoque diferente.\n",
        "    # Una opción es asumir valores por defecto o predecirlos por separado si fuera posible\n",
        "    # sin depender de otros factores que no sean la fecha.\n",
        "    # Dado que el modelo de clasificación de Random Forest predice la probabilidad de cada clase,\n",
        "    # podemos dejar que el modelo prediga estas categorías.\n",
        "\n",
        "    # Por ahora, nos aseguramos de que las columnas one-hot encoded existan y sean False por defecto\n",
        "    # (excepto la del día de la semana que acabamos de establecer si corresponde).\n",
        "    for col in X_columns:\n",
        "        if col not in future_processed.columns:\n",
        "            future_processed[col] = False # Inicializar con False\n",
        "\n",
        "    # Asegurar que todas las columnas sean numéricas (booleanos se tratan como 0/1)\n",
        "    future_processed = future_processed.astype(float)\n",
        "\n",
        "\n",
        "    return future_processed\n",
        "\n",
        "\n",
        "# Función para realizar predicciones para una fecha futura\n",
        "def predict_future(future_date_str, trained_models, X_columns):\n",
        "    \"\"\"\n",
        "    Realiza predicciones para una fecha futura utilizando los modelos entrenados.\n",
        "    Incluye una estimación de la desviación estándar para la predicción de perros.\n",
        "    \"\"\"\n",
        "    future_data_processed = preprocess_future_date(future_date_str, X_columns)\n",
        "\n",
        "    predictions = {}\n",
        "    for target_variable, model in trained_models.items():\n",
        "        if target_variable in ['numero_perros_teckel', 'estancias_largas', 'temperatura_celsius']:\n",
        "            # Predicción para variables de regresión\n",
        "            predictions[f'predicted_{target_variable}'] = model.predict(future_data_processed)[0]\n",
        "\n",
        "            # Si es la predicción de perros, calcular la desviación estándar de las predicciones de los árboles\n",
        "            if target_variable == 'numero_perros_teckel':\n",
        "                 tree_predictions = [tree.predict(future_data_processed)[0] for tree in model.estimators_]\n",
        "                 predictions['numero_perros_teckel_std_dev'] = np.std(tree_predictions)\n",
        "                 # predictions['numero_perros_teckel_tree_predictions'] = tree_predictions # Opcional: guardar las predicciones de cada árbol\n",
        "\n",
        "        elif model.__class__.__name__ == 'RandomForestClassifier':\n",
        "            # Predicción para variables de clasificación\n",
        "            # Predecir la probabilidad de cada clase\n",
        "            probabilities = model.predict_proba(future_data_processed)[0]\n",
        "            # Obtener el índice de la clase con mayor probabilidad\n",
        "            predicted_class_index = np.argmax(probabilities)\n",
        "            # Obtener el nombre de la clase predicha (True/False para columnas dummy)\n",
        "            predicted_class_encoded = model.classes_[predicted_class_index]\n",
        "            probability_predicted_class = probabilities[predicted_class_index]\n",
        "\n",
        "\n",
        "            # Asignar las predicciones al diccionario\n",
        "            if target_variable.startswith('dia_semana_'):\n",
        "                 # Para el día de la semana, necesitamos encontrar cuál columna de día_semana_ tiene la mayor probabilidad de ser True\n",
        "                 day_probs = {col.replace('dia_semana_', ''): model.predict_proba(future_data_processed)[0][1]\n",
        "                              for col, model in trained_models.items() if col.startswith('dia_semana_') and model.__class__.__name__ == 'RandomForestClassifier'}\n",
        "                 # Añadir Domingo si no fue dropeado y tiene su propio clasificador (aunque en este caso fue dropeado)\n",
        "                 # Si Domingo fue dropeado, su \"predicción\" implícita es cuando todas las demás son False.\n",
        "                 # Sin embargo, la forma más robusta es ver cuál de las columnas que *tenemos* tiene la mayor probabilidad de ser True.\n",
        "                 # Si ninguna tiene alta probabilidad, podría sugerir la clase dropeada si es común.\n",
        "\n",
        "                 # Una mejor manera: predecir la clase más probable entre TODAS las categorías originales\n",
        "                 # Esto requiere entrenar un clasificador multiclase para 'dia_semana' en lugar de binarios para cada día.\n",
        "                 # Dado que entrenamos clasificadores binarios, interpretaremos las probabilidades de ser True.\n",
        "\n",
        "                 # Encontrar el día de la semana con la mayor probabilidad de ser True\n",
        "                 predicted_day = 'Domingo' # Asumimos Domingo por defecto si todas las columnas dia_semana_ son False\n",
        "                 max_day_prob = 0.0\n",
        "                 for day_col in [col for col in trained_models.keys() if col.startswith('dia_semana_')]:\n",
        "                     # Asegurarse de que el modelo para este día exista\n",
        "                     if day_col in trained_models and trained_models[day_col].__class__.__name__ == 'RandomForestClassifier':\n",
        "                          prob_true = trained_models[day_col].predict_proba(future_data_processed)[0][1]\n",
        "                          if prob_true > max_day_prob:\n",
        "                              max_day_prob = prob_true\n",
        "                              predicted_day = day_col.replace('dia_semana_', '')\n",
        "\n",
        "                 predictions['predicted_dia_semana'] = predicted_day\n",
        "                 predictions['probability_dia_semana'] = max_day_prob # Probabilidad del día predicho\n",
        "\n",
        "            elif target_variable.startswith('motivo_estancia_'):\n",
        "                 motivo_probs = {col.replace('motivo_estancia_', ''): model.predict_proba(future_data_processed)[0][1]\n",
        "                                 for col, model in trained_models.items() if col.startswith('motivo_estancia_') and model.__class__.__name__ == 'RandomForestClassifier'}\n",
        "                 if motivo_probs:\n",
        "                      predicted_motivo = max(motivo_probs, key=motivo_probs.get)\n",
        "                      predictions['predicted_motivo_estancia'] = predicted_motivo\n",
        "                      predictions['probability_motivo_estancia'] = motivo_probs[predicted_motivo]\n",
        "                 else:\n",
        "                      predictions['predicted_motivo_estancia'] = 'Desconocido'\n",
        "                      predictions['probability_motivo_estancia'] = 0.0\n",
        "\n",
        "            elif target_variable.startswith('condicion_climatica_'):\n",
        "                 condicion_probs = {col.replace('condicion_climatica_', ''): model.predict_proba(future_data_processed)[0][1]\n",
        "                                    for col, model in trained_models.items() if col.startswith('condicion_climatica_') and model.__class__.__name__ == 'RandomForestClassifier'}\n",
        "                 if condicion_probs:\n",
        "                      predicted_condicion = max(condicion_probs, key=condicion_probs.get)\n",
        "                      predictions['predicted_condicion_climatica'] = predicted_condicion\n",
        "                      predictions['probability_condicion_climatica'] = condicion_probs[predicted_condicion]\n",
        "                 else:\n",
        "                      predictions['predicted_condicion_climatica'] = 'Desconocido'\n",
        "                      predictions['probability_condicion_climatica'] = 0.0\n",
        "\n",
        "            elif target_variable == 'evento_especial_True':\n",
        "                 # Para evento_especial_True, la predicción es si es True o False basada en la probabilidad\n",
        "                 prob_true = model.predict_proba(future_data_processed)[0][1] # Probabilidad de que sea True\n",
        "                 predictions['predicted_evento_especial'] = 'Sí' if prob_true > 0.5 else 'No' # Umbral simple del 50%\n",
        "                 predictions['probability_evento_especial_True'] = prob_true # Probabilidad de que el evento especial sea True\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# --- Ejemplo de uso (puedes cambiar la fecha aquí) ---\n",
        "future_date_to_predict = str(input(\"Ingrese la fecha a pronosticar\")) # '2025-12-20' Cambia esta fecha a la que desees predecir\n",
        "\n",
        "# Pasamos X.columns a la función de preprocesamiento\n",
        "future_date_prediction = predict_future(future_date_to_predict, trained_models, X.columns)\n",
        "\n",
        "# Mostrar las predicciones\n",
        "print(f\"Predicciones para la fecha: {future_date_to_predict}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Día de la semana predicho: {future_date_prediction.get('predicted_dia_semana', 'N/A')} (Probabilidad: {future_date_prediction.get('probability_dia_semana', 0.0):.2f})\")\n",
        "print(f\"Número de perros Teckel predicho: {future_date_prediction.get('predicted_numero_perros_teckel', 'N/A'):.2f}\")\n",
        "print(f\"Desviación estándar de la predicción de perros: {future_date_prediction.get('numero_perros_teckel_std_dev', 'N/A'):.2f}\")\n",
        "print(f\"Estancias largas predichas: {future_date_prediction.get('predicted_estancias_largas', 'N/A'):.2f}\")\n",
        "print(f\"Temperatura predicha (Celsius): {future_date_prediction.get('predicted_temperatura_celsius', 'N/A'):.2f}\")\n",
        "print(f\"Condición climática predicha: {future_date_prediction.get('predicted_condicion_climatica', 'N/A')} (Probabilidad: {future_date_prediction.get('probability_condicion_climatica', 0.0):.2f})\")\n",
        "print(f\"Motivo de estancia predicho: {future_date_prediction.get('predicted_motivo_estancia', 'N/A')} (Probabilidad: {future_date_prediction.get('probability_motivo_estancia', 0.0):.2f})\")\n",
        "print(f\"Evento especial predicho: {future_date_prediction.get('predicted_evento_especial', 'N/A')} (Probabilidad de True: {future_date_prediction.get('probability_evento_especial_True', 0.0):.2f})\") # Cambiado a probability_evento_especial_True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "from datetime import date, timedelta\n",
        "from google.colab import drive # Importar drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir el directorio en tu Google Drive donde quieres guardar el archivo\n",
        "# Reemplaza 'Your_Folder_Name' con el nombre real de la carpeta en tu Drive\n",
        "drive_path = '/content/drive/My Drive/Your_Folder_Name/simulated_data.csv'\n",
        "\n",
        "\n",
        "# Nombres de las columnas\n",
        "column_names = [\n",
        "    \"fecha\",\n",
        "    \"dia_semana\",\n",
        "    \"numero_perros_teckel\",\n",
        "    \"estancias_largas\",\n",
        "    \"motivo_estancia\",\n",
        "    \"evento_especial\",\n",
        "    \"temperatura_celsius\",\n",
        "    \"condicion_climatica\"\n",
        "]\n",
        "\n",
        "# Días de la semana en español\n",
        "dias_semana = {\n",
        "    0: \"Lunes\",\n",
        "    1: \"Martes\",\n",
        "    2: \"Miércoles\",\n",
        "    3: \"Jueves\",\n",
        "    4: \"Viernes\",\n",
        "    5: \"Sábado\",\n",
        "    6: \"Domingo\"\n",
        "}\n",
        "\n",
        "# Posibles motivos de estancia\n",
        "motivos_estancia = [\"Vacaciones\", \"Trabajo\"]\n",
        "\n",
        "# Posibles condiciones climáticas\n",
        "condiciones_climaticas = [\"Soleado\", \"Nublado\", \"Lluvia\"]\n",
        "\n",
        "# Función para generar datos simulados para un día\n",
        "def generar_fila_datos(current_date):\n",
        "    \"\"\"\n",
        "    Genera una fila de datos simulados para un día específico.\n",
        "    Los valores se basan en la fecha y el día de la semana para mayor realismo.\n",
        "    \"\"\"\n",
        "    day_of_week = current_date.weekday()\n",
        "    dia_semana_str = dias_semana[day_of_week]\n",
        "\n",
        "    # Mayor cantidad de perros en fines de semana y temporada alta\n",
        "    is_weekend = day_of_week >= 5\n",
        "    is_vacation_month = current_date.month in [6, 7, 12] # Junio, Julio, Diciembre\n",
        "\n",
        "    if is_weekend or is_vacation_month:\n",
        "        numero_perros = random.randint(10, 20)\n",
        "        motivo = \"Vacaciones\"\n",
        "    else:\n",
        "        numero_perros = random.randint(5, 12)\n",
        "        motivo = random.choice(motivos_estancia)\n",
        "\n",
        "    # Estancias largas es un subconjunto de perros totales\n",
        "    estancias_largas = random.randint(3, numero_perros - 2) if numero_perros > 5 else 0\n",
        "\n",
        "    # Evento especial (aleatorio, puede coincidir con festivos)\n",
        "    evento_especial = \"Sí\" if random.random() < 0.05 else \"No\"\n",
        "\n",
        "    # Simular un aumento de temperatura en meses cálidos\n",
        "    if current_date.month in [6, 7, 8]:\n",
        "        temperatura = random.randint(28, 35)\n",
        "    elif current_date.month in [1, 2, 11, 12]:\n",
        "        temperatura = random.randint(18, 25)\n",
        "    else:\n",
        "        temperatura = random.randint(22, 30)\n",
        "\n",
        "    # Condición climática aleatoria\n",
        "    condicion_climatica = random.choice(condiciones_climaticas)\n",
        "\n",
        "    # Devolver la fila como una lista de valores\n",
        "    return [\n",
        "        current_date.strftime(\"%Y-%m-%d\"),\n",
        "        dia_semana_str,\n",
        "        numero_perros,\n",
        "        estancias_largas,\n",
        "        motivo,\n",
        "        evento_especial,\n",
        "        temperatura,\n",
        "        condicion_climatica\n",
        "    ]\n",
        "\n",
        "# Configuración del año 2020 (que es un año bisiesto)\n",
        "start_date = date(2020, 1, 1)\n",
        "end_date = date(2020, 12, 31)\n",
        "delta = timedelta(days=1)\n",
        "\n",
        "# Crear el contenido CSV\n",
        "csv_data = []\n",
        "csv_data.append(column_names)\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "    csv_data.append(generar_fila_datos(current_date))\n",
        "    current_date += delta\n",
        "\n",
        "# Guardar los datos en un archivo CSV en Google Drive\n",
        "with open(drive_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(csv_data)\n",
        "\n",
        "print(f\"Datos guardados en {drive_path}\")"
      ],
      "metadata": {
        "id": "A4bn06QZa2AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f629e088"
      },
      "source": [
        "### 1. Exploración Inicial de Datos\n",
        "Vamos a mostrar las estadísticas descriptivas y la estructura del DataFrame `data_processed` para tener una primera idea de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8821b777"
      },
      "source": [
        "# Mostrar las primeras filas del DataFrame\n",
        "print(\"Primeras 5 filas del DataFrame data_processed:\")\n",
        "display(data_processed.head())\n",
        "\n",
        "# Mostrar información general del DataFrame (tipos de datos, valores no nulos)\n",
        "print(\"\\nInformación del DataFrame data_processed:\")\n",
        "data_processed.info()\n",
        "\n",
        "# Mostrar estadísticas descriptivas para las columnas numéricas\n",
        "print(\"\\nEstadísticas descriptivas del DataFrame data_processed:\")\n",
        "display(data_processed.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16ffa692"
      },
      "source": [
        "### 2. Análisis de Correlación\n",
        "Vamos a calcular la matriz de correlación para las variables numéricas y visualizarla usando un mapa de calor. Esto nos ayudará a identificar relaciones lineales entre las variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9095f1c8"
      },
      "source": [
        "# Seleccionar solo las columnas numéricas para el análisis de correlación\n",
        "# Excluimos las columnas booleanas que representan variables categóricas codificadas\n",
        "numeric_cols = data_processed.select_dtypes(include=np.number)\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = numeric_cols.corr()\n",
        "\n",
        "# Mostrar la matriz de correlación\n",
        "print(\"Matriz de correlación de las variables numéricas:\")\n",
        "display(correlation_matrix)\n",
        "\n",
        "# Visualizar la matriz de correlación usando un mapa de calor\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Matriz de Correlación de Variables Numéricas')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8f18ce8"
      },
      "source": [
        "### 3. Análisis de Variables Categóricas\n",
        "\n",
        "Vamos a examinar la distribución de las variables categóricas codificadas y su relación con algunas de las variables objetivo clave como `numero_perros_teckel` y `estancias_largas`. Utilizaremos gráficos de barras y/o box plots para visualizar estas relaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b673a13"
      },
      "source": [
        "# Variables categóricas codificadas de interés (excluyendo las que ya son variables objetivo directas)\n",
        "categorical_features = [col for col in data_processed.columns if data_processed[col].dtype == 'bool' and col not in target_variables.keys()]\n",
        "\n",
        "print(\"Análisis de variables categóricas y su relación con las variables objetivo:\")\n",
        "\n",
        "# Analizar la relación de cada variable categórica con las variables objetivo clave\n",
        "target_reg_vars = ['numero_perros_teckel', 'estancias_largas']\n",
        "\n",
        "for cat_col in categorical_features:\n",
        "    print(f\"\\nAnálisis para la variable categórica: {cat_col}\")\n",
        "\n",
        "    for target_var in target_reg_vars:\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        # Usamos boxplot para ver la distribución de la variable objetivo para cada categoría (True/False)\n",
        "        sns.boxplot(x=cat_col, y=target_var, data=data_processed)\n",
        "        plt.title(f'{target_var} vs {cat_col}')\n",
        "        plt.xlabel(cat_col)\n",
        "        plt.ylabel(target_var)\n",
        "        plt.show()\n",
        "\n",
        "# Además, podemos ver la distribución de las categorías originales antes de la codificación one-hot\n",
        "# Esto requiere usar el DataFrame 'data' original\n",
        "print(\"\\nDistribución de las variables categóricas originales:\")\n",
        "for original_cat_col in ['dia_semana', 'motivo_estancia', 'condicion_climatica', 'evento_especial']:\n",
        "    if original_cat_col in data.columns:\n",
        "        print(f\"\\nDistribución de '{original_cat_col}':\")\n",
        "        display(data[original_cat_col].value_counts())\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.countplot(x=original_cat_col, data=data, order=data[original_cat_col].value_counts().index)\n",
        "        plt.title(f'Distribución de {original_cat_col}')\n",
        "        plt.xlabel(original_cat_col)\n",
        "        plt.ylabel('Frecuencia')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9d91928"
      },
      "source": [
        "### Visualización de la Cantidad de Perros Teckel a lo Largo del Tiempo\n",
        "\n",
        "Vamos a crear un gráfico de series de tiempo para visualizar la cantidad diaria de perros Teckel (`numero_perros_teckel`) a lo largo de todas las fechas disponibles en el conjunto de datos. Esto nos ayudará a identificar tendencias, estacionalidad o picos inusuales en la cantidad de perros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac08e215"
      },
      "source": [
        "# Asegurarnos de que la columna 'fecha' sea de tipo datetime (ya lo hicimos, pero es buena práctica confirmarlo)\n",
        "data['fecha'] = pd.to_datetime(data['fecha'])\n",
        "\n",
        "# Establecer la columna 'fecha' como índice para facilitar el trazado de series de tiempo\n",
        "data_sorted = data.sort_values('fecha')\n",
        "\n",
        "# Crear el gráfico de series de tiempo\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.lineplot(x='fecha', y='numero_perros_teckel', data=data_sorted)\n",
        "plt.title('Cantidad de Perros Teckel a lo Largo del Tiempo')\n",
        "plt.xlabel('Fecha')\n",
        "plt.ylabel('Número de Perros Teckel')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}